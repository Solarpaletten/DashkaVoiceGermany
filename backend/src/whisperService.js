const OpenAI = require('openai');
const fs = require('fs');
const path = require('path');

class WhisperService {
  constructor() {
    if (process.env.OPENAI_API_KEY) {
      this.openai = new OpenAI({
        apiKey: process.env.OPENAI_API_KEY
      });
      console.log('üé§ Whisper Service initialized (OpenAI API)');
    } else {
      this.openai = null;
      console.log('üé§ Whisper Service initialized (mock mode - no API key)');
    }
    
    this.supportedLanguages = ['en', 'ru', 'de', 'es', 'cs', 'pl', 'lt', 'lv', 'no'];
  }

  async transcribe(audioFilePath, language = 'auto') {
    try {
      // –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
      if (!fs.existsSync(audioFilePath)) {
        throw new Error('Audio file not found');
      }

      // –ï—Å–ª–∏ –Ω–µ—Ç OpenAI API –∫–ª—é—á–∞, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∑–∞–≥–ª—É—à–∫—É
      if (!this.openai) {
        console.log('‚ö†Ô∏è No OpenAI API key, using mock transcription');
        const mockTexts = {
          'ru': '–î–æ–±—Ä—ã–π –¥–µ–Ω—å, —Ö–æ—Ç–µ–ª –±—ã —Å–¥–∞—Ç—å –æ—Ç—á—ë—Ç–Ω–æ—Å—Ç—å –ø–æ –Ω–∞–ª–æ–≥–∞–º',
          'de': 'Guten Tag, ich m√∂chte meine Steuererkl√§rung abgeben',
          'en': 'Good day, I would like to submit my tax return',
          'auto': 'Sample transcription for testing purposes'
        };
        
        return {
          text: mockTexts[language] || mockTexts['auto'],
          language: language === 'auto' ? 'ru' : language,
          confidence: 0.95,
          duration: 3.0,
          provider: 'mock-whisper'
        };
      }

      // –†–µ–∞–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ Whisper API
      console.log(`üé§ Transcribing audio file: ${path.basename(audioFilePath)}`);
      
      const transcription = await this.openai.audio.transcriptions.create({
        file: fs.createReadStream(audioFilePath),
        model: 'whisper-1',
        language: language === 'auto' ? undefined : language,
        response_format: 'json',
        temperature: 0.2
      });

      console.log(`üìù Transcription result: "${transcription.text}"`);

      return {
        text: transcription.text,
        language: transcription.language || language,
        confidence: 0.95,
        duration: transcription.duration || 5.0,
        provider: 'openai-whisper-1'
      };

    } catch (error) {
      console.error('Whisper Error:', error.message);
      
      // Fallback –∫ –∑–∞–≥–ª—É—à–∫–µ –ø—Ä–∏ –æ—à–∏–±–∫–µ
      console.log('üîÑ Falling back to mock transcription due to error');
      const fallbackTexts = {
        'ru': '–ü—Ä–∏–º–µ—Ä —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ',
        'de': 'Beispieltext auf Deutsch',
        'en': 'Sample text in English',
        'auto': 'Error fallback transcription'
      };
      
      return {
        text: fallbackTexts[language] || fallbackTexts['auto'],
        language: language === 'auto' ? 'ru' : language,
        confidence: 0.5,
        duration: 3.0,
        provider: 'fallback-mock',
        error: error.message
      };
    }
  }

  // –ú–µ—Ç–æ–¥ –¥–ª—è –ø—Ä—è–º–æ–≥–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –≤–≤–æ–¥–∞ (–æ–±—Ö–æ–¥ –∞—É–¥–∏–æ)
  async transcribeText(text, language = 'auto') {
    console.log(`üìù Direct text input: "${text}"`);
    
    return {
      text: text,
      language: language === 'auto' ? 'ru' : language,
      confidence: 1.0,
      duration: 0,
      provider: 'direct-text-input'
    };
  }
}

// –°–æ–∑–¥–∞–µ–º –µ–¥–∏–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä
const whisperService = new WhisperService();

// –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
async function transcribeAudio(audioFilePath, language = 'auto') {
  const result = await whisperService.transcribe(audioFilePath, language);
  return result.text;
}

// –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä—è–º–æ–≥–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –≤–≤–æ–¥–∞
async function transcribeText(text, language = 'auto') {
  const result = await whisperService.transcribeText(text, language);
  return result.text;
}

module.exports = {
  transcribeAudio,
  transcribeText,
  WhisperService,
  whisperService
};